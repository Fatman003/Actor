2020-05-17 15:44:33,768: root: DEBUG: PBS job id: None
2020-05-17 15:44:33,769: root: DEBUG: SLURM job id: None
2020-05-17 15:44:44,670: root: DEBUG: PBS job id: None
2020-05-17 15:44:44,670: root: DEBUG: SLURM job id: None
2020-05-17 15:44:44,779: pykwalify.core: INFO: validation.valid
2020-05-17 15:44:44,784: pykwalify.core: INFO: validation.valid
2020-05-17 15:44:44,789: pykwalify.core: INFO: validation.valid
2020-05-17 15:44:44,793: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7efd1af6f950>,
              'config_path': 'configs/ted12.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7efce9139a10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7efce91399d0: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'stages': {'annealing': {'training': {'num_epochs': 20, 'restart_from': '_best', 'scale': 0.0001}},
            'main': {'training': {'num_epochs': 20}}},
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 15:44:44,796: lvsr.main: INFO: Stage "main" config:
{'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7efce913a410: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7efce913a190: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'num_epochs': 20,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 15:51:17,646: root: DEBUG: PBS job id: None
2020-05-17 15:51:17,646: root: DEBUG: SLURM job id: None
2020-05-17 15:51:17,721: pykwalify.core: INFO: validation.valid
2020-05-17 15:51:17,726: pykwalify.core: INFO: validation.valid
2020-05-17 15:51:17,731: pykwalify.core: INFO: validation.valid
2020-05-17 15:51:17,734: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f503cc14950>,
              'config_path': 'configs/ted12.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f500addea10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f500adde9d0: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'stages': {'annealing': {'training': {'num_epochs': 20, 'restart_from': '_best', 'scale': 0.0001}},
            'main': {'training': {'num_epochs': 20}}},
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 15:51:17,735: lvsr.main: INFO: Training is resumed from stage main
2020-05-17 15:51:17,737: lvsr.main: INFO: Stage "main" config:
{'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f500addf410: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f500addf190: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'num_epochs': 20,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 16:10:05,879: root: DEBUG: PBS job id: None
2020-05-17 16:10:05,879: root: DEBUG: SLURM job id: None
2020-05-17 16:10:05,961: pykwalify.core: INFO: validation.valid
2020-05-17 16:10:05,967: pykwalify.core: INFO: validation.valid
2020-05-17 16:10:05,972: pykwalify.core: INFO: validation.valid
2020-05-17 16:10:05,975: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f697cac9950>,
              'config_path': 'configs/ted12.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac93a10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f694ac939d0: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'stages': {'annealing': {'training': {'num_epochs': 20, 'restart_from': '_best', 'scale': 0.0001}},
            'main': {'training': {'num_epochs': 20}}},
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 16:10:05,975: lvsr.main: INFO: Training is resumed from stage main
2020-05-17 16:10:05,977: lvsr.main: INFO: Stage "main" config:
{'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'num_epochs': 20,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 16:10:16,302: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-17 16:10:16,310: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f694ac94410: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f694ac94190: mean=0.0, width=0.1>}
2020-05-17 16:10:16,728: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-17 16:10:16,729: lvsr.main: INFO: Cost graph is built
2020-05-17 16:10:16,772: lvsr.main: INFO: Load parameters from ted12/main.tar
2020-05-17 16:13:45,395: root: DEBUG: PBS job id: None
2020-05-17 16:13:45,395: root: DEBUG: SLURM job id: None
2020-05-17 16:13:45,479: pykwalify.core: INFO: validation.valid
2020-05-17 16:13:45,482: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f1f4e115950>,
              'config_path': 'configs/reinforce2.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'reinforce', 'reward': 'delta_bleu'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'extra_generation_steps': 3,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 16:13:56,017: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-17 16:13:56,026: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                           'bleureward': {},
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'value_prediction': {'biases_init': <blocks.initialization.Constant object at 0x7f1f1c2d1a10: constant=0.0>,
                                                'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f1f1c2d19d0: mean=0.0, width=0.1>}
2020-05-17 16:14:02,985: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-17 16:14:02,986: lvsr.main: INFO: Cost graph is built
2020-05-17 16:14:03,087: lvsr.main: INFO: Parameters
[('/recognizer/bottom/lookuptable.W', (32039, 256)),
 ('/recognizer/convencoder.loc_comp', (700, 256)),
 ('/recognizer/convencoder.padding', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/energy_comp/linear.W', (256, 1)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.b', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/state_trans/transform_states.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/transition.initial_state', (256,)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_gates', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_state', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.b', (512,)),
 ('/recognizer/generator/feedback/fork/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_inputs.b', (256,)),
 ('/recognizer/generator/feedback/lookuptable.W', (22811, 256)),
 ('/recognizer/generator/readout/bias.b', (22810,)),
 ('/recognizer/generator/readout/merge/transform_states.W', (256, 22810)),
 ('/recognizer/generator/readout/merge/transform_weighted_averages.W', (256, 22810)),
 ('/recognizer/generator/readout/value_prediction.W', (256, 1)),
 ('/recognizer/generator/readout/value_prediction.b', (1,))]
2020-05-17 16:14:03,087: lvsr.main: INFO: Using ADAM for training
2020-05-17 16:14:03,088: blocks.algorithms: INFO: Taking the cost gradient
2020-05-17 16:14:04,147: blocks.algorithms: INFO: The cost gradient computation graph is built
2020-05-17 16:14:04,180: blocks.algorithms: DEBUG: Computing parameter steps...
2020-05-17 16:14:04,606: lvsr.main: DEBUG: There are updates in the computation graph
2020-05-17 16:14:04,607: lvsr.main: DEBUG: Scan Ops in the gradients
2020-05-17 16:14:04,722: lvsr.main: DEBUG: for{cpu,generator_generate_scan}
2020-05-17 16:14:04,723: lvsr.main: DEBUG: for{cpu,attentionrecurrent_do_apply_scan}
2020-05-17 16:14:04,723: lvsr.main: DEBUG: for{cpu,grad_of_attentionrecurrent_do_apply_scan}
2020-05-17 16:14:04,734: lvsr.main: INFO: Initialize extensions
2020-05-17 16:17:56,677: root: DEBUG: PBS job id: None
2020-05-17 16:17:56,677: root: DEBUG: SLURM job id: None
2020-05-17 16:17:56,751: pykwalify.core: INFO: validation.valid
2020-05-17 16:17:56,754: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f08402d7950>,
              'config_path': 'configs/reinforce2.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'reinforce', 'reward': 'delta_bleu'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'extra_generation_steps': 3,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 16:18:07,056: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-17 16:18:07,064: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                           'bleureward': {},
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'value_prediction': {'biases_init': <blocks.initialization.Constant object at 0x7f080e4ada10: constant=0.0>,
                                                'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f080e4ad9d0: mean=0.0, width=0.1>}
2020-05-17 16:18:08,337: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-17 16:18:08,339: lvsr.main: INFO: Cost graph is built
2020-05-17 16:18:08,439: lvsr.main: INFO: Parameters
[('/recognizer/bottom/lookuptable.W', (32039, 256)),
 ('/recognizer/convencoder.loc_comp', (700, 256)),
 ('/recognizer/convencoder.padding', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/energy_comp/linear.W', (256, 1)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.b', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/state_trans/transform_states.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/transition.initial_state', (256,)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_gates', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_state', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.b', (512,)),
 ('/recognizer/generator/feedback/fork/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_inputs.b', (256,)),
 ('/recognizer/generator/feedback/lookuptable.W', (22811, 256)),
 ('/recognizer/generator/readout/bias.b', (22810,)),
 ('/recognizer/generator/readout/merge/transform_states.W', (256, 22810)),
 ('/recognizer/generator/readout/merge/transform_weighted_averages.W', (256, 22810)),
 ('/recognizer/generator/readout/value_prediction.W', (256, 1)),
 ('/recognizer/generator/readout/value_prediction.b', (1,))]
2020-05-17 16:18:08,439: lvsr.main: INFO: Using ADAM for training
2020-05-17 16:18:08,440: blocks.algorithms: INFO: Taking the cost gradient
2020-05-17 16:18:09,467: blocks.algorithms: INFO: The cost gradient computation graph is built
2020-05-17 16:18:09,473: blocks.algorithms: DEBUG: Computing parameter steps...
2020-05-17 16:18:09,883: lvsr.main: DEBUG: There are updates in the computation graph
2020-05-17 16:18:09,884: lvsr.main: DEBUG: Scan Ops in the gradients
2020-05-17 16:18:09,996: lvsr.main: DEBUG: for{cpu,generator_generate_scan}
2020-05-17 16:18:09,996: lvsr.main: DEBUG: for{cpu,attentionrecurrent_do_apply_scan}
2020-05-17 16:18:09,996: lvsr.main: DEBUG: for{cpu,grad_of_attentionrecurrent_do_apply_scan}
2020-05-17 16:18:10,008: lvsr.main: INFO: Initialize extensions
2020-05-17 16:18:16,198: blocks.main_loop: INFO: Entered the main loop
2020-05-17 16:18:16,736: blocks.algorithms: INFO: Initializing the training algorithm
2020-05-17 16:18:16,737: blocks.algorithms: DEBUG: Inferring graph inputs...
2020-05-17 16:18:16,980: blocks.algorithms: DEBUG: Compiling training function...
2020-05-17 16:18:50,540: blocks.algorithms: INFO: The training algorithm is initialized
2020-05-17 16:18:50,551: lvsr.extensions: INFO: Computation graph statistics:
2020-05-17 16:18:50,681: lvsr.extensions: INFO: SCAN NODES IN THE COST GRAPH:
2020-05-17 16:18:50,681: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 16:18:50,681: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 16:18:50,682: lvsr.extensions: INFO: SCAN NODES IN THE UPDATES GRAPH:
2020-05-17 16:18:50,682: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 16:18:50,682: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 16:18:50,682: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-17 16:18:50,682: lvsr.extensions: INFO: SCAN NODES IN THE FINAL GRAPH:
2020-05-17 16:18:50,682: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-17 16:18:50,682: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 16:18:50,682: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 16:18:50,682: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-17 17:14:23,456: root: DEBUG: PBS job id: None
2020-05-17 17:14:23,484: root: DEBUG: SLURM job id: None
2020-05-17 17:14:23,603: pykwalify.core: INFO: validation.valid
2020-05-17 17:14:23,607: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f36cc3cf950>,
              'config_path': 'configs/reinforce2.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'reinforce', 'reward': 'delta_bleu'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'extra_generation_steps': 3,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 17:14:34,422: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-17 17:14:34,431: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                           'bleureward': {},
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'value_prediction': {'biases_init': <blocks.initialization.Constant object at 0x7f369a5a5a10: constant=0.0>,
                                                'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f369a5a59d0: mean=0.0, width=0.1>}
2020-05-17 17:14:43,329: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-17 17:14:43,331: lvsr.main: INFO: Cost graph is built
2020-05-17 17:14:43,448: lvsr.main: INFO: Parameters
[('/recognizer/bottom/lookuptable.W', (32039, 256)),
 ('/recognizer/convencoder.loc_comp', (700, 256)),
 ('/recognizer/convencoder.padding', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/energy_comp/linear.W', (256, 1)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.b', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/state_trans/transform_states.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/transition.initial_state', (256,)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_gates', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_state', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.b', (512,)),
 ('/recognizer/generator/feedback/fork/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_inputs.b', (256,)),
 ('/recognizer/generator/feedback/lookuptable.W', (22811, 256)),
 ('/recognizer/generator/readout/bias.b', (22810,)),
 ('/recognizer/generator/readout/merge/transform_states.W', (256, 22810)),
 ('/recognizer/generator/readout/merge/transform_weighted_averages.W', (256, 22810)),
 ('/recognizer/generator/readout/value_prediction.W', (256, 1)),
 ('/recognizer/generator/readout/value_prediction.b', (1,))]
2020-05-17 17:14:43,449: lvsr.main: INFO: Using ADAM for training
2020-05-17 17:14:43,449: blocks.algorithms: INFO: Taking the cost gradient
2020-05-17 17:14:44,524: blocks.algorithms: INFO: The cost gradient computation graph is built
2020-05-17 17:14:44,554: blocks.algorithms: DEBUG: Computing parameter steps...
2020-05-17 17:14:44,970: lvsr.main: DEBUG: There are updates in the computation graph
2020-05-17 17:14:44,971: lvsr.main: DEBUG: Scan Ops in the gradients
2020-05-17 17:14:45,087: lvsr.main: DEBUG: for{cpu,generator_generate_scan}
2020-05-17 17:14:45,087: lvsr.main: DEBUG: for{cpu,attentionrecurrent_do_apply_scan}
2020-05-17 17:14:45,087: lvsr.main: DEBUG: for{cpu,grad_of_attentionrecurrent_do_apply_scan}
2020-05-17 17:14:45,099: lvsr.main: INFO: Initialize extensions
2020-05-17 17:14:51,292: blocks.main_loop: INFO: Entered the main loop
2020-05-17 17:14:52,129: blocks.algorithms: INFO: Initializing the training algorithm
2020-05-17 17:14:52,130: blocks.algorithms: DEBUG: Inferring graph inputs...
2020-05-17 17:14:52,375: blocks.algorithms: DEBUG: Compiling training function...
2020-05-17 17:15:26,786: blocks.algorithms: INFO: The training algorithm is initialized
2020-05-17 17:15:26,806: lvsr.extensions: INFO: Computation graph statistics:
2020-05-17 17:15:26,937: lvsr.extensions: INFO: SCAN NODES IN THE COST GRAPH:
2020-05-17 17:15:26,937: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 17:15:26,937: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 17:15:26,937: lvsr.extensions: INFO: SCAN NODES IN THE UPDATES GRAPH:
2020-05-17 17:15:26,937: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 17:15:26,937: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 17:15:26,937: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-17 17:15:26,937: lvsr.extensions: INFO: SCAN NODES IN THE FINAL GRAPH:
2020-05-17 17:15:26,938: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-17 17:15:26,938: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 17:15:26,938: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 17:15:26,938: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-17 19:47:40,425: root: DEBUG: PBS job id: None
2020-05-17 19:47:40,446: root: DEBUG: SLURM job id: None
2020-05-17 19:47:40,555: pykwalify.core: INFO: validation.valid
2020-05-17 19:47:40,558: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f998e739990>,
              'config_path': 'configs/reinforce2.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'reinforce', 'reward': 'delta_bleu'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'extra_generation_steps': 3,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-17 19:47:50,181: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-17 19:47:50,188: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                           'bleureward': {},
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'value_prediction': {'biases_init': <blocks.initialization.Constant object at 0x7f995c90fa50: constant=0.0>,
                                                'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f995c90fa10: mean=0.0, width=0.1>}
2020-05-17 19:47:58,994: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-17 19:47:58,996: lvsr.main: INFO: Cost graph is built
2020-05-17 19:47:59,094: lvsr.main: INFO: Parameters
[('/recognizer/bottom/lookuptable.W', (32039, 256)),
 ('/recognizer/convencoder.loc_comp', (700, 256)),
 ('/recognizer/convencoder.padding', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/energy_comp/linear.W', (256, 1)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.b', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/state_trans/transform_states.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/transition.initial_state', (256,)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_gates', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_state', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.b', (512,)),
 ('/recognizer/generator/feedback/fork/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_inputs.b', (256,)),
 ('/recognizer/generator/feedback/lookuptable.W', (22811, 256)),
 ('/recognizer/generator/readout/bias.b', (22810,)),
 ('/recognizer/generator/readout/merge/transform_states.W', (256, 22810)),
 ('/recognizer/generator/readout/merge/transform_weighted_averages.W', (256, 22810)),
 ('/recognizer/generator/readout/value_prediction.W', (256, 1)),
 ('/recognizer/generator/readout/value_prediction.b', (1,))]
2020-05-17 19:47:59,095: lvsr.main: INFO: Using ADAM for training
2020-05-17 19:47:59,095: blocks.algorithms: INFO: Taking the cost gradient
2020-05-17 19:48:00,036: blocks.algorithms: INFO: The cost gradient computation graph is built
2020-05-17 19:48:00,053: blocks.algorithms: DEBUG: Computing parameter steps...
2020-05-17 19:48:00,428: lvsr.main: DEBUG: There are updates in the computation graph
2020-05-17 19:48:00,429: lvsr.main: DEBUG: Scan Ops in the gradients
2020-05-17 19:48:00,528: lvsr.main: DEBUG: for{cpu,generator_generate_scan}
2020-05-17 19:48:00,529: lvsr.main: DEBUG: for{cpu,attentionrecurrent_do_apply_scan}
2020-05-17 19:48:00,529: lvsr.main: DEBUG: for{cpu,grad_of_attentionrecurrent_do_apply_scan}
2020-05-17 19:48:00,539: lvsr.main: INFO: Initialize extensions
2020-05-17 19:48:06,166: blocks.main_loop: INFO: Entered the main loop
2020-05-17 19:48:06,911: blocks.algorithms: INFO: Initializing the training algorithm
2020-05-17 19:48:06,912: blocks.algorithms: DEBUG: Inferring graph inputs...
2020-05-17 19:48:07,132: blocks.algorithms: DEBUG: Compiling training function...
2020-05-17 19:48:36,694: blocks.algorithms: INFO: The training algorithm is initialized
2020-05-17 19:48:36,704: lvsr.extensions: INFO: Computation graph statistics:
2020-05-17 19:48:36,817: lvsr.extensions: INFO: SCAN NODES IN THE COST GRAPH:
2020-05-17 19:48:36,818: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: SCAN NODES IN THE UPDATES GRAPH:
2020-05-17 19:48:36,818: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: SCAN NODES IN THE FINAL GRAPH:
2020-05-17 19:48:36,818: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-17 19:48:36,818: lvsr.extensions: INFO: generator_generate_scan
2020-05-17 19:48:36,819: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-17 20:55:08,876: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data finished
2020-05-17 20:55:12,120: blocks.extensions.training: DEBUG: TrackTheBest: current value of log.current_row["valid_sequence_total_cost"] = None
2020-05-17 20:55:12,198: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-18 03:31:38,011: root: DEBUG: PBS job id: None
2020-05-18 03:31:38,032: root: DEBUG: SLURM job id: None
2020-05-18 03:31:38,143: pykwalify.core: INFO: validation.valid
2020-05-18 03:31:38,145: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7fcd6fc8b990>,
              'config_path': 'configs/reinforced2.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'reinforce', 'reward': 'delta_bleu'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'extra_generation_steps': 3,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.0001}}
2020-05-18 03:31:47,821: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-18 03:31:47,829: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                           'bleureward': {},
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'value_prediction': {'biases_init': <blocks.initialization.Constant object at 0x7fcd3de5da50: constant=0.0>,
                                                'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
                           'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7fcd3de5db90: mean=0.0, width=0.1>}
2020-05-18 03:31:56,528: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-18 03:31:56,529: lvsr.main: INFO: Cost graph is built
2020-05-18 03:31:56,626: lvsr.main: INFO: Parameters
[('/recognizer/bottom/lookuptable.W', (32039, 256)),
 ('/recognizer/convencoder.loc_comp', (700, 256)),
 ('/recognizer/convencoder.padding', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/energy_comp/linear.W', (256, 1)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.b', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/state_trans/transform_states.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/transition.initial_state', (256,)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_gates', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_state', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.b', (512,)),
 ('/recognizer/generator/feedback/fork/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_inputs.b', (256,)),
 ('/recognizer/generator/feedback/lookuptable.W', (22811, 256)),
 ('/recognizer/generator/readout/bias.b', (22810,)),
 ('/recognizer/generator/readout/merge/transform_states.W', (256, 22810)),
 ('/recognizer/generator/readout/merge/transform_weighted_averages.W', (256, 22810)),
 ('/recognizer/generator/readout/value_prediction.W', (256, 1)),
 ('/recognizer/generator/readout/value_prediction.b', (1,))]
2020-05-18 03:31:56,626: lvsr.main: INFO: Using ADAM for training
2020-05-18 03:31:56,627: blocks.algorithms: INFO: Taking the cost gradient
2020-05-18 03:31:57,554: blocks.algorithms: INFO: The cost gradient computation graph is built
2020-05-18 03:31:57,574: blocks.algorithms: DEBUG: Computing parameter steps...
2020-05-18 03:31:57,947: lvsr.main: DEBUG: There are updates in the computation graph
2020-05-18 03:31:57,947: lvsr.main: DEBUG: Scan Ops in the gradients
2020-05-18 03:31:58,046: lvsr.main: DEBUG: for{cpu,generator_generate_scan}
2020-05-18 03:31:58,046: lvsr.main: DEBUG: for{cpu,attentionrecurrent_do_apply_scan}
2020-05-18 03:31:58,046: lvsr.main: DEBUG: for{cpu,grad_of_attentionrecurrent_do_apply_scan}
2020-05-18 03:31:58,056: lvsr.main: INFO: Initialize extensions
2020-05-18 03:32:03,739: blocks.main_loop: INFO: Entered the main loop
2020-05-18 03:32:04,376: blocks.algorithms: INFO: Initializing the training algorithm
2020-05-18 03:32:04,377: blocks.algorithms: DEBUG: Inferring graph inputs...
2020-05-18 03:32:04,592: blocks.algorithms: DEBUG: Compiling training function...
2020-05-18 03:32:33,785: blocks.algorithms: INFO: The training algorithm is initialized
2020-05-18 03:32:33,794: lvsr.extensions: INFO: Computation graph statistics:
2020-05-18 03:32:33,906: lvsr.extensions: INFO: SCAN NODES IN THE COST GRAPH:
2020-05-18 03:32:33,906: lvsr.extensions: INFO: generator_generate_scan
2020-05-18 03:32:33,906: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-18 03:32:33,906: lvsr.extensions: INFO: SCAN NODES IN THE UPDATES GRAPH:
2020-05-18 03:32:33,906: lvsr.extensions: INFO: generator_generate_scan
2020-05-18 03:32:33,906: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-18 03:32:33,907: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-18 03:32:33,907: lvsr.extensions: INFO: SCAN NODES IN THE FINAL GRAPH:
2020-05-18 03:32:33,907: lvsr.extensions: INFO: generator_generate_scan
2020-05-18 03:32:33,907: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-18 03:32:33,907: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-18 03:32:33,907: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-18 04:39:41,953: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data finished
2020-05-18 04:39:43,453: blocks.extensions.training: DEBUG: TrackTheBest: current value of log.current_row["valid_sequence_total_cost"] = None
2020-05-18 04:39:43,575: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-18 15:07:00,557: root: DEBUG: PBS job id: None
2020-05-18 15:07:00,579: root: DEBUG: SLURM job id: None
2020-05-18 15:07:00,686: pykwalify.core: INFO: validation.valid
2020-05-18 15:07:00,688: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7efe55aa9990>,
              'config_path': 'configs/reinforced2.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'reinforce', 'reward': 'delta_bleu'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'extra_generation_steps': 3,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.0001}}
2020-05-18 15:07:10,100: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-18 15:07:10,108: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                           'bleureward': {},
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'value_prediction': {'biases_init': <blocks.initialization.Constant object at 0x7efe23c7ba50: constant=0.0>,
                                                'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
                           'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7efe23c7bb90: mean=0.0, width=0.1>}
2020-05-18 15:07:19,161: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-18 15:07:19,163: lvsr.main: INFO: Cost graph is built
2020-05-18 15:07:19,262: lvsr.main: INFO: Parameters
[('/recognizer/bottom/lookuptable.W', (32039, 256)),
 ('/recognizer/convencoder.loc_comp', (700, 256)),
 ('/recognizer/convencoder.padding', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/energy_comp/linear.W', (256, 1)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/cont_att/preprocess.b', (256,)),
 ('/recognizer/generator/attentionrecurrent/cont_att/state_trans/transform_states.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/distribute/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/attentionrecurrent/transition.initial_state', (256,)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_gates', (256, 512)),
 ('/recognizer/generator/attentionrecurrent/transition.state_to_state', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.W', (256, 512)),
 ('/recognizer/generator/feedback/fork/fork_gate_inputs.b', (512,)),
 ('/recognizer/generator/feedback/fork/fork_inputs.W', (256, 256)),
 ('/recognizer/generator/feedback/fork/fork_inputs.b', (256,)),
 ('/recognizer/generator/feedback/lookuptable.W', (22811, 256)),
 ('/recognizer/generator/readout/bias.b', (22810,)),
 ('/recognizer/generator/readout/merge/transform_states.W', (256, 22810)),
 ('/recognizer/generator/readout/merge/transform_weighted_averages.W', (256, 22810)),
 ('/recognizer/generator/readout/value_prediction.W', (256, 1)),
 ('/recognizer/generator/readout/value_prediction.b', (1,))]
2020-05-18 15:07:19,262: lvsr.main: INFO: Using ADAM for training
2020-05-18 15:07:19,263: blocks.algorithms: INFO: Taking the cost gradient
2020-05-18 15:07:20,189: blocks.algorithms: INFO: The cost gradient computation graph is built
2020-05-18 15:07:20,210: blocks.algorithms: DEBUG: Computing parameter steps...
2020-05-18 15:07:20,580: lvsr.main: DEBUG: There are updates in the computation graph
2020-05-18 15:07:20,580: lvsr.main: DEBUG: Scan Ops in the gradients
2020-05-18 15:07:20,679: lvsr.main: DEBUG: for{cpu,generator_generate_scan}
2020-05-18 15:07:20,679: lvsr.main: DEBUG: for{cpu,attentionrecurrent_do_apply_scan}
2020-05-18 15:07:20,679: lvsr.main: DEBUG: for{cpu,grad_of_attentionrecurrent_do_apply_scan}
2020-05-18 15:07:20,690: lvsr.main: INFO: Initialize extensions
2020-05-18 15:07:26,153: blocks.main_loop: INFO: Entered the main loop
2020-05-18 15:07:26,934: blocks.algorithms: INFO: Initializing the training algorithm
2020-05-18 15:07:26,935: blocks.algorithms: DEBUG: Inferring graph inputs...
2020-05-18 15:07:27,152: blocks.algorithms: DEBUG: Compiling training function...
2020-05-18 15:07:56,442: blocks.algorithms: INFO: The training algorithm is initialized
2020-05-18 15:07:56,452: lvsr.extensions: INFO: Computation graph statistics:
2020-05-18 15:07:56,565: lvsr.extensions: INFO: SCAN NODES IN THE COST GRAPH:
2020-05-18 15:07:56,565: lvsr.extensions: INFO: generator_generate_scan
2020-05-18 15:07:56,565: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-18 15:07:56,565: lvsr.extensions: INFO: SCAN NODES IN THE UPDATES GRAPH:
2020-05-18 15:07:56,565: lvsr.extensions: INFO: generator_generate_scan
2020-05-18 15:07:56,565: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-18 15:07:56,565: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-18 15:07:56,565: lvsr.extensions: INFO: SCAN NODES IN THE FINAL GRAPH:
2020-05-18 15:07:56,565: lvsr.extensions: INFO: grad_of_attentionrecurrent_do_apply_scan
2020-05-18 15:07:56,566: lvsr.extensions: INFO: generator_generate_scan
2020-05-18 15:07:56,566: lvsr.extensions: INFO: attentionrecurrent_do_apply_scan
2020-05-18 15:07:56,566: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-18 16:15:07,375: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data finished
2020-05-18 16:15:10,002: blocks.extensions.training: DEBUG: TrackTheBest: current value of log.current_row["valid_sequence_total_cost"] = None
2020-05-18 16:15:10,126: blocks.extensions.monitoring: INFO: Monitoring on auxiliary data started
2020-05-18 21:00:46,724: root: DEBUG: PBS job id: None
2020-05-18 21:00:46,748: root: DEBUG: SLURM job id: None
2020-05-18 21:00:46,855: pykwalify.core: INFO: validation.valid
2020-05-18 21:00:46,860: pykwalify.core: INFO: validation.valid
2020-05-18 21:00:46,864: pykwalify.core: INFO: validation.valid
2020-05-18 21:00:46,868: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f7feee9a990>,
              'config_path': 'configs/ted12.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f7fbd064a50: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f7fbd064a10: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'stages': {'annealing': {'training': {'num_epochs': 20, 'restart_from': '_best', 'scale': 0.0001}},
            'main': {'training': {'num_epochs': 20}}},
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-18 21:00:46,880: lvsr.main: INFO: Training is resumed from stage main
2020-05-18 21:00:46,883: lvsr.main: INFO: Stage "main" config:
{'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'num_epochs': 20,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-05-18 21:00:56,657: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-05-18 21:00:56,664: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f7feee2fcd0: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f7feee2fb10: mean=0.0, width=0.1>}
2020-05-18 21:00:57,120: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-05-18 21:00:57,121: lvsr.main: INFO: Cost graph is built
2020-05-18 21:00:57,176: lvsr.main: INFO: Load parameters from ted12/main.tar
2020-06-03 21:22:10,347: root: DEBUG: PBS job id: None
2020-06-03 21:22:10,347: root: DEBUG: SLURM job id: None
2020-06-03 21:22:10,436: pykwalify.core: INFO: validation.valid
2020-06-03 21:22:10,441: pykwalify.core: INFO: validation.valid
2020-06-03 21:22:10,447: pykwalify.core: INFO: validation.valid
2020-06-03 21:22:10,450: __main__: INFO: Config:
{'cmd_args': {'bokeh': 0,
              'bokeh_name': '',
              'bokeh_server': None,
              'config_changes': <picklable_itertools.extras.equizip object at 0x7f706e5bcd90>,
              'config_path': 'configs/ted12.yaml',
              'debug_mode': False,
              'fast_start': False,
              'final_stage': None,
              'func': 'train_multistage',
              'load_log': False,
              'params': None,
              'save_path': 'ted12',
              'start_stage': '',
              'test_tag': None,
              'use_load_ext': False,
              'validate_config': True},
 'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f703fffa1d0: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f703fffa190: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'stages': {'annealing': {'training': {'num_epochs': 20, 'restart_from': '_best', 'scale': 0.0001}},
            'main': {'training': {'num_epochs': 20}}},
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-06-03 21:22:10,450: lvsr.main: INFO: Training is resumed from stage main
2020-06-03 21:22:10,452: lvsr.main: INFO: Stage "main" config:
{'data': {'add_bos': 1,
          'add_eos': True,
          'batch_size': 32,
          'dataset_class': <class 'lvsr.datasets.mt.H5PyMTDataset'>,
          'dataset_filename': 'TED/de-en/ted.h5',
          'default_sources': ['inputs', 'labels'],
          'name_mapping': {'test': 'test', 'train': 'train', 'valid': 'dev'},
          'sources_map': {'inputs': 'sources', 'labels': 'targets'},
          'validation_batch_size': 256},
 'initialization': {'/recognizer': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>}},
 'monitoring': {'primary_freq': 100,
                'search': {'beam_size': 1, 'metric': 'bleu', 'stop_on': 'optimistic_future_cost'},
                'search_every_batches': 0,
                'search_every_epochs': 1,
                'search_on_training': 3000,
                'secondary_freq': 100,
                'validate_every_batches': 0,
                'validate_every_epochs': 1},
 'net': {'attention_type': 'content',
         'bottom': {'bottom_class': <class 'lvsr.bricks.recognizer.LookupBottom'>, 'dim': 256},
         'criterion': {'name': 'log_likelihood'},
         'dec_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'dim_dec': 256,
         'dims_bidir': None,
         'enc_transition': <class 'blocks.bricks.recurrent.architectures.GatedRecurrent'>,
         'lm': {},
         'max_decoded_length_scale': 0.75,
         'max_length': 700,
         'use_states_for_readout': True,
         'window_size': 5},
 'parent': '$LVSR/exp/ted/configs/ted1.yaml',
 'training': {'decay_rate': 0.999,
              'epsilon': 1e-06,
              'gradient_threshold': 0.0,
              'momentum': 0.9,
              'num_epochs': 20,
              'rules': ['adam'],
              'save_every_epochs': 1,
              'scale': 0.001}}
2020-06-03 21:22:24,196: lvsr.main: INFO: Initialization schemes for all bricks.
Works well only in my branch with __repr__ added to all them,
there is an issue #463 in Blocks to do that properly.
2020-06-03 21:22:24,204: lvsr.main: INFO: {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
 'bottom': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                            'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
            'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
 'convencoder': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                 'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
 'generator': {'attentionrecurrent': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                      'cont_att': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                   'energy_comp': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                   'linear': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                              'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                                   'tanh': {},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                   'preprocess': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                  'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                   'state_trans': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                   'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                                        'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                   'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                      'distribute': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                      'transition': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                     'logistic': {},
                                                     'tanh': {},
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                      'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
               'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
               'feedback': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                            'fork': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                     'fork_gate_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                     'fork_inputs': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                            'lookuptable': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                            'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                            'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
               'readout': {'bias': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                    'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                           'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                           'merge': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                     'transform_states': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                          'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                     'transform_weighted_averages': {'biases_init': <blocks.initialization.Constant object at 0x7f706e5a9ad0: constant=0.0>,
                                                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                                     'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
                           'ndimensionalsoftmax': {},
                           'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
               'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>},
 'initial_states_init': None,
 'rec_weights_init': None,
 'softmax': {},
 'top': {},
 'weights_init': <blocks.initialization.Uniform object at 0x7f706e554410: mean=0.0, width=0.1>}
2020-06-03 21:22:24,581: lvsr.bricks.recognizer: DEBUG: Switching back to the normal mode
2020-06-03 21:22:24,582: lvsr.main: INFO: Cost graph is built
2020-06-03 21:22:24,627: lvsr.main: INFO: Load parameters from ted12/main.tar
